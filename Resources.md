# Resources

Resources from the web

# General/Multi
## Collections of AI resources, including tools, models, implementations 
https://github.com/awe50me/Awesome-AI
https://github.com/steven2358/awesome-generative-ai
https://github.com/yunwei37/prompt-hacker-collections

## Learning resources
https://github.com/amusi/awesome-ai-awesomeness
https://github.com/owainlewis/awesome-artificial-intelligence
https://github.com/visenger/awesome-mlops

Prompt Injection Primers
https://github.com/jthack/PIPE
https://github.com/Cranot/chatbot-injections-exploits
https://github.com/TakSec/Prompt-Injection-Everywhere

## Finance:
https://github.com/georgezouq/awesome-ai-in-finance

# Prompt engineering
https://github.com/unbiarirang/Fixed-Input-Parameterization

# Attacks
Big list of ML attacks @csima
https://gist.github.com/csima/b5ea16b682f6117c11debee7c40fa8fc

"tasks where language models get worse as they become better at language modeling (next word prediction)"
https://github.com/mivanit/inverse-scaling-prompt-injection

Injection with special tokens
https://github.com/sunghun7511/chatgpt-prompt-injection

Stored injection POC
https://github.com/JosephTLucas/stored_prompt_injection/blob/main/stored_prompt_injection.ipynb

# Research
The Carlini Collection
https://nicholas.carlini.com/writing/2019/all-adversarial-example-papers.html

Exploiting Programmatic Behavior of LLMs: Dual-Use Through Standard Security Attacks
Kang, Li, Stoica, Guestrin, Zaharia, Hashimoto
https://arxiv.org/pdf/2302.05733.pdf
"instruction-following LLMs can produce targeted malicious content, including hate
speech and scams, bypassing in-the-wild defenses
implemented by LLM API vendors."


#Offensive AI
Compilation of resources covering Offensive AI
https://github.com/jiep/offensive-ai-compilation

# Build
Building LLM applications for production -  Chip Huyen
https://huyenchip.com/2023/04/11/llm-engineering.html

LLMs, Embeddings, Context Injection, and Next Generation OER
https://opencontent.org/blog/archives/7205

This guy's YouTube has a ton of enbeddings/build/use advice
https://www.youtube.com/@RabbitHoleSyndrome 

# Governance
NIST crosswalk
https://airc.nist.gov/AI_RMF_Knowledge_Base/Crosswalks

NIST 800-160v1r1 Engineering Trustworthy Secure Systems
https://nvlpubs.nist.gov/nistpubs/SpecialPublications/NIST.SP.800-160v1r1.pdf

NIST AI RMF
https://nvlpubs.nist.gov/nistpubs/ai/NIST.AI.100-1.pdf

NIST Taxonomy of AI Risk (Draft)
https://www.nist.gov/system/files/documents/2021/10/15/taxonomy_AI_risks.pdf

CISA Proposed Shared Responsibility Model
https://cloudsecurityalliance.org/blog/2023/07/28/generative-ai-proposed-shared-responsibility-model/

ENISA Multilayer Framework for Good Cybersecurity Practices for AI
https://www.enisa.europa.eu/publications/multilayer-framework-for-good-cybersecurity-practices-for-ai

# Model Cards
https://modelcards.withgoogle.com/about
https://huggingface.co/blog/model-cards
https://arxiv.org/pdf/1810.03993.pdf
https://github.com/fau-masters-collected-works-cgarbin/model-card-template
https://github.com/ivylee/model-cards-and-datasheets
https://docs.aws.amazon.com/sagemaker/latest/dg/model-cards.html
https://ai.meta.com/blog/system-cards-a-new-resource-for-understanding-how-ai-systems-work/


# Threat Modeling
Threat Modeling AI Systems
Gavin Klondike
https://aivillage.org/large%20language%20models/threat-modeling-llm/

# M/SDLC
Supply-chain Levels for Software Artifacts (SLSA) 
https://slsa.dev/

Securing the ML Lifecycle, Industry IoT Consortium
https://www.iiconsortium.org/news-pdf/joi-articles/2022-March-JoI-Securing-the-ML-Lifecycle.pdf

Integrating Machine Learning With Software Development Lifecycles: Insights From Experts
Late, Mantymaki, Minkkinen, Birkstedt
https://www.researchgate.net/publication/360318448_Integrating_Machine_Learning_With_Software_Development_Lifecycles_Insights_From_Experts
"This paper examines the challenges related to integrating machine learning (ML) development with software development lifecycle (SDLC) models."

# Defense
https://github.com/Valhall-ai/prompt-injection-mitigations

# Tools
https://github.com/pgvector/pgvector
https://github.com/openai/evals
https://github.com/openai/chatgpt-retrieval-plugin
https://github.com/openai/triton
https://github.com/yoheinakajima/babyagi
https://github.com/Significant-Gravitas/AutoGPT
https://github.com/imartinez/privateGPT
https://github.com/go-skynet/LocalAI
https://github.com/utyvert/mailbuddy


Prompt Injection defense:
https://github.com/protectai/rebuff

Prompt injection target:
https://github.com/svenmorgenrothio/Prompt-Injection-Playground

Prompt injection harness:
https://github.com/LLMSecurity/HouYi
https://github.com/utkusen/promptmap

# Prompts
## Non offense
https://huggingface.co/datasets/fka/awesome-chatgpt-prompts
https://huggingface.co/datasets/succinctly/midjourney-prompts
https://huggingface.co/datasets/daspartho/stable-diffusion-prompts

## Negative test
https://huggingface.co/datasets/notrichardren/refuse-to-answer-prompts

## Jailbreak
https://huggingface.co/datasets/rubend18/ChatGPT-Jailbreak-Prompts

## Toxicity
https://huggingface.co/datasets/allenai/real-toxicity-prompts
https://huggingface.co/datasets/PanoEvJ/real-toxicity-prompts-severe0.7

## Generate/run code
https://huggingface.co/datasets/LangChainHub-Prompts/LLM_Bash
https://huggingface.co/datasets/agie-ai/awesome-chatgpt-prompts
https://huggingface.co/datasets/kaxap/llama2-sql-instruct-sys-prompt

## Prompt injection
https://huggingface.co/datasets/deepset/prompt-injections
https://huggingface.co/datasets/imoxto/prompt_injection_cleaned_dataset
https://huggingface.co/datasets/imoxto/prompt_injection_cleaned_dataset-v2
https://huggingface.co/datasets/imoxto/prompt_injection_hackaprompt_gpt35
https://huggingface.co/datasets/cgoosen/prompt_injection_password_or_secret
https://huggingface.co/datasets/boardsec/prompt-injection-duplicate-default
https://huggingface.co/datasets/JasperLS/prompt-injections

## Gandalf and duck
https://github.com/tpai/gandalf-prompt-injection-writeup
https://github.com/Prajwalsrinvas/prompt-injection





